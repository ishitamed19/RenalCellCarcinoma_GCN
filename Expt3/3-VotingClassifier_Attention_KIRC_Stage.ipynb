{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VotingClassifier_MAE_Attention_KIRC_Stage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIj6v4m3nXGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb5i9BOIobpS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XWpVXAfBkI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "34de18cf-aac6-4f8e-c2a6-7842733f8a98"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 17263742484818979107\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 2414708622469230962\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8643644680654248969\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11150726272\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 9212446338165112643\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SGfUwtfBzpf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c24a3873-ff65-4339-cf61-c4d6d8524645"
      },
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "# tf.debugging.set_log_device_placement(True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr9O-MzWn3ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/IIITH/GCN_KEGG/KIRC_Stage_TSNE_PCA_Plots/Patient_Matrices'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRgQwB_PolGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = '/content/drive/My Drive/IIITH/GCN_KEGG/KIRC_Stage_TSNE_PCA_Plots/labels.csv'\n",
        "y = pd.read_csv(labels, header=None)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLUl-y7lpi8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = []\n",
        "test_x = []"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncUn8dKQpPjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2497ad1-4ec9-46ba-a732-79eac49063a0"
      },
      "source": [
        "for patient in range(515):\n",
        "  filename = str(patient) + '.csv'\n",
        "  print(filename)\n",
        "  df = pd.read_csv(os.path.join(path,str(filename)), header=None)\n",
        "  if patient<412:\n",
        "    train_x.append(df.to_numpy())\n",
        "  else:\n",
        "    test_x.append(df.to_numpy())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.csv\n",
            "1.csv\n",
            "2.csv\n",
            "3.csv\n",
            "4.csv\n",
            "5.csv\n",
            "6.csv\n",
            "7.csv\n",
            "8.csv\n",
            "9.csv\n",
            "10.csv\n",
            "11.csv\n",
            "12.csv\n",
            "13.csv\n",
            "14.csv\n",
            "15.csv\n",
            "16.csv\n",
            "17.csv\n",
            "18.csv\n",
            "19.csv\n",
            "20.csv\n",
            "21.csv\n",
            "22.csv\n",
            "23.csv\n",
            "24.csv\n",
            "25.csv\n",
            "26.csv\n",
            "27.csv\n",
            "28.csv\n",
            "29.csv\n",
            "30.csv\n",
            "31.csv\n",
            "32.csv\n",
            "33.csv\n",
            "34.csv\n",
            "35.csv\n",
            "36.csv\n",
            "37.csv\n",
            "38.csv\n",
            "39.csv\n",
            "40.csv\n",
            "41.csv\n",
            "42.csv\n",
            "43.csv\n",
            "44.csv\n",
            "45.csv\n",
            "46.csv\n",
            "47.csv\n",
            "48.csv\n",
            "49.csv\n",
            "50.csv\n",
            "51.csv\n",
            "52.csv\n",
            "53.csv\n",
            "54.csv\n",
            "55.csv\n",
            "56.csv\n",
            "57.csv\n",
            "58.csv\n",
            "59.csv\n",
            "60.csv\n",
            "61.csv\n",
            "62.csv\n",
            "63.csv\n",
            "64.csv\n",
            "65.csv\n",
            "66.csv\n",
            "67.csv\n",
            "68.csv\n",
            "69.csv\n",
            "70.csv\n",
            "71.csv\n",
            "72.csv\n",
            "73.csv\n",
            "74.csv\n",
            "75.csv\n",
            "76.csv\n",
            "77.csv\n",
            "78.csv\n",
            "79.csv\n",
            "80.csv\n",
            "81.csv\n",
            "82.csv\n",
            "83.csv\n",
            "84.csv\n",
            "85.csv\n",
            "86.csv\n",
            "87.csv\n",
            "88.csv\n",
            "89.csv\n",
            "90.csv\n",
            "91.csv\n",
            "92.csv\n",
            "93.csv\n",
            "94.csv\n",
            "95.csv\n",
            "96.csv\n",
            "97.csv\n",
            "98.csv\n",
            "99.csv\n",
            "100.csv\n",
            "101.csv\n",
            "102.csv\n",
            "103.csv\n",
            "104.csv\n",
            "105.csv\n",
            "106.csv\n",
            "107.csv\n",
            "108.csv\n",
            "109.csv\n",
            "110.csv\n",
            "111.csv\n",
            "112.csv\n",
            "113.csv\n",
            "114.csv\n",
            "115.csv\n",
            "116.csv\n",
            "117.csv\n",
            "118.csv\n",
            "119.csv\n",
            "120.csv\n",
            "121.csv\n",
            "122.csv\n",
            "123.csv\n",
            "124.csv\n",
            "125.csv\n",
            "126.csv\n",
            "127.csv\n",
            "128.csv\n",
            "129.csv\n",
            "130.csv\n",
            "131.csv\n",
            "132.csv\n",
            "133.csv\n",
            "134.csv\n",
            "135.csv\n",
            "136.csv\n",
            "137.csv\n",
            "138.csv\n",
            "139.csv\n",
            "140.csv\n",
            "141.csv\n",
            "142.csv\n",
            "143.csv\n",
            "144.csv\n",
            "145.csv\n",
            "146.csv\n",
            "147.csv\n",
            "148.csv\n",
            "149.csv\n",
            "150.csv\n",
            "151.csv\n",
            "152.csv\n",
            "153.csv\n",
            "154.csv\n",
            "155.csv\n",
            "156.csv\n",
            "157.csv\n",
            "158.csv\n",
            "159.csv\n",
            "160.csv\n",
            "161.csv\n",
            "162.csv\n",
            "163.csv\n",
            "164.csv\n",
            "165.csv\n",
            "166.csv\n",
            "167.csv\n",
            "168.csv\n",
            "169.csv\n",
            "170.csv\n",
            "171.csv\n",
            "172.csv\n",
            "173.csv\n",
            "174.csv\n",
            "175.csv\n",
            "176.csv\n",
            "177.csv\n",
            "178.csv\n",
            "179.csv\n",
            "180.csv\n",
            "181.csv\n",
            "182.csv\n",
            "183.csv\n",
            "184.csv\n",
            "185.csv\n",
            "186.csv\n",
            "187.csv\n",
            "188.csv\n",
            "189.csv\n",
            "190.csv\n",
            "191.csv\n",
            "192.csv\n",
            "193.csv\n",
            "194.csv\n",
            "195.csv\n",
            "196.csv\n",
            "197.csv\n",
            "198.csv\n",
            "199.csv\n",
            "200.csv\n",
            "201.csv\n",
            "202.csv\n",
            "203.csv\n",
            "204.csv\n",
            "205.csv\n",
            "206.csv\n",
            "207.csv\n",
            "208.csv\n",
            "209.csv\n",
            "210.csv\n",
            "211.csv\n",
            "212.csv\n",
            "213.csv\n",
            "214.csv\n",
            "215.csv\n",
            "216.csv\n",
            "217.csv\n",
            "218.csv\n",
            "219.csv\n",
            "220.csv\n",
            "221.csv\n",
            "222.csv\n",
            "223.csv\n",
            "224.csv\n",
            "225.csv\n",
            "226.csv\n",
            "227.csv\n",
            "228.csv\n",
            "229.csv\n",
            "230.csv\n",
            "231.csv\n",
            "232.csv\n",
            "233.csv\n",
            "234.csv\n",
            "235.csv\n",
            "236.csv\n",
            "237.csv\n",
            "238.csv\n",
            "239.csv\n",
            "240.csv\n",
            "241.csv\n",
            "242.csv\n",
            "243.csv\n",
            "244.csv\n",
            "245.csv\n",
            "246.csv\n",
            "247.csv\n",
            "248.csv\n",
            "249.csv\n",
            "250.csv\n",
            "251.csv\n",
            "252.csv\n",
            "253.csv\n",
            "254.csv\n",
            "255.csv\n",
            "256.csv\n",
            "257.csv\n",
            "258.csv\n",
            "259.csv\n",
            "260.csv\n",
            "261.csv\n",
            "262.csv\n",
            "263.csv\n",
            "264.csv\n",
            "265.csv\n",
            "266.csv\n",
            "267.csv\n",
            "268.csv\n",
            "269.csv\n",
            "270.csv\n",
            "271.csv\n",
            "272.csv\n",
            "273.csv\n",
            "274.csv\n",
            "275.csv\n",
            "276.csv\n",
            "277.csv\n",
            "278.csv\n",
            "279.csv\n",
            "280.csv\n",
            "281.csv\n",
            "282.csv\n",
            "283.csv\n",
            "284.csv\n",
            "285.csv\n",
            "286.csv\n",
            "287.csv\n",
            "288.csv\n",
            "289.csv\n",
            "290.csv\n",
            "291.csv\n",
            "292.csv\n",
            "293.csv\n",
            "294.csv\n",
            "295.csv\n",
            "296.csv\n",
            "297.csv\n",
            "298.csv\n",
            "299.csv\n",
            "300.csv\n",
            "301.csv\n",
            "302.csv\n",
            "303.csv\n",
            "304.csv\n",
            "305.csv\n",
            "306.csv\n",
            "307.csv\n",
            "308.csv\n",
            "309.csv\n",
            "310.csv\n",
            "311.csv\n",
            "312.csv\n",
            "313.csv\n",
            "314.csv\n",
            "315.csv\n",
            "316.csv\n",
            "317.csv\n",
            "318.csv\n",
            "319.csv\n",
            "320.csv\n",
            "321.csv\n",
            "322.csv\n",
            "323.csv\n",
            "324.csv\n",
            "325.csv\n",
            "326.csv\n",
            "327.csv\n",
            "328.csv\n",
            "329.csv\n",
            "330.csv\n",
            "331.csv\n",
            "332.csv\n",
            "333.csv\n",
            "334.csv\n",
            "335.csv\n",
            "336.csv\n",
            "337.csv\n",
            "338.csv\n",
            "339.csv\n",
            "340.csv\n",
            "341.csv\n",
            "342.csv\n",
            "343.csv\n",
            "344.csv\n",
            "345.csv\n",
            "346.csv\n",
            "347.csv\n",
            "348.csv\n",
            "349.csv\n",
            "350.csv\n",
            "351.csv\n",
            "352.csv\n",
            "353.csv\n",
            "354.csv\n",
            "355.csv\n",
            "356.csv\n",
            "357.csv\n",
            "358.csv\n",
            "359.csv\n",
            "360.csv\n",
            "361.csv\n",
            "362.csv\n",
            "363.csv\n",
            "364.csv\n",
            "365.csv\n",
            "366.csv\n",
            "367.csv\n",
            "368.csv\n",
            "369.csv\n",
            "370.csv\n",
            "371.csv\n",
            "372.csv\n",
            "373.csv\n",
            "374.csv\n",
            "375.csv\n",
            "376.csv\n",
            "377.csv\n",
            "378.csv\n",
            "379.csv\n",
            "380.csv\n",
            "381.csv\n",
            "382.csv\n",
            "383.csv\n",
            "384.csv\n",
            "385.csv\n",
            "386.csv\n",
            "387.csv\n",
            "388.csv\n",
            "389.csv\n",
            "390.csv\n",
            "391.csv\n",
            "392.csv\n",
            "393.csv\n",
            "394.csv\n",
            "395.csv\n",
            "396.csv\n",
            "397.csv\n",
            "398.csv\n",
            "399.csv\n",
            "400.csv\n",
            "401.csv\n",
            "402.csv\n",
            "403.csv\n",
            "404.csv\n",
            "405.csv\n",
            "406.csv\n",
            "407.csv\n",
            "408.csv\n",
            "409.csv\n",
            "410.csv\n",
            "411.csv\n",
            "412.csv\n",
            "413.csv\n",
            "414.csv\n",
            "415.csv\n",
            "416.csv\n",
            "417.csv\n",
            "418.csv\n",
            "419.csv\n",
            "420.csv\n",
            "421.csv\n",
            "422.csv\n",
            "423.csv\n",
            "424.csv\n",
            "425.csv\n",
            "426.csv\n",
            "427.csv\n",
            "428.csv\n",
            "429.csv\n",
            "430.csv\n",
            "431.csv\n",
            "432.csv\n",
            "433.csv\n",
            "434.csv\n",
            "435.csv\n",
            "436.csv\n",
            "437.csv\n",
            "438.csv\n",
            "439.csv\n",
            "440.csv\n",
            "441.csv\n",
            "442.csv\n",
            "443.csv\n",
            "444.csv\n",
            "445.csv\n",
            "446.csv\n",
            "447.csv\n",
            "448.csv\n",
            "449.csv\n",
            "450.csv\n",
            "451.csv\n",
            "452.csv\n",
            "453.csv\n",
            "454.csv\n",
            "455.csv\n",
            "456.csv\n",
            "457.csv\n",
            "458.csv\n",
            "459.csv\n",
            "460.csv\n",
            "461.csv\n",
            "462.csv\n",
            "463.csv\n",
            "464.csv\n",
            "465.csv\n",
            "466.csv\n",
            "467.csv\n",
            "468.csv\n",
            "469.csv\n",
            "470.csv\n",
            "471.csv\n",
            "472.csv\n",
            "473.csv\n",
            "474.csv\n",
            "475.csv\n",
            "476.csv\n",
            "477.csv\n",
            "478.csv\n",
            "479.csv\n",
            "480.csv\n",
            "481.csv\n",
            "482.csv\n",
            "483.csv\n",
            "484.csv\n",
            "485.csv\n",
            "486.csv\n",
            "487.csv\n",
            "488.csv\n",
            "489.csv\n",
            "490.csv\n",
            "491.csv\n",
            "492.csv\n",
            "493.csv\n",
            "494.csv\n",
            "495.csv\n",
            "496.csv\n",
            "497.csv\n",
            "498.csv\n",
            "499.csv\n",
            "500.csv\n",
            "501.csv\n",
            "502.csv\n",
            "503.csv\n",
            "504.csv\n",
            "505.csv\n",
            "506.csv\n",
            "507.csv\n",
            "508.csv\n",
            "509.csv\n",
            "510.csv\n",
            "511.csv\n",
            "512.csv\n",
            "513.csv\n",
            "514.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se7UEOUKqHxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = np.asarray(train_x)\n",
        "test_x = np.asarray(test_x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKmM2d6UvSll",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "48447f33-0741-453a-be16-4967604b9c8b"
      },
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((412, 24, 2), (103, 24, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0i8Dj00fy8u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "b76cdca0-4a57-41ff-af84-3d1ef8a4a63c"
      },
      "source": [
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "0    0.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "3    0.0\n",
              "4    1.0\n",
              "..   ...\n",
              "510  0.0\n",
              "511  0.0\n",
              "512  0.0\n",
              "513  0.0\n",
              "514  0.0\n",
              "\n",
              "[515 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxEsei-qDVDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = y.values\n",
        "Y = Y.astype('float32') "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwJbhXynvhXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a6123394-bc5c-4b61-e2c8-a36e963f8a25"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(515, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "888FV4OQIwuw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fb1fc95-b1b5-43b5-9d76-ddad1f45cb58"
      },
      "source": [
        "Y"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvDKO9A0Ql9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_x, test_x = X[0:412], X[412:]\n",
        "train_y, test_y = Y[0:412], Y[412:]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gIRetxSxOw_",
        "colab_type": "text"
      },
      "source": [
        "# Custom Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-K3IqbIxeII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwXGsAV4wB8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining pathway attention\n",
        "\n",
        "class Pathway_Attention(layers.Layer):\n",
        "\n",
        "  def __init__(self, a, d, p):\n",
        "    super(Pathway_Attention, self).__init__()\n",
        "    self.units = a\n",
        "    self.input_dim = d\n",
        "    self.alpha_dim = p\n",
        "\n",
        "    self.w = self.add_weight(shape=(self.input_dim, self.units),\n",
        "                             initializer='random_normal',\n",
        "                             trainable=True)\n",
        "    self.b = self.add_weight(shape=(self.units,),\n",
        "                             initializer='zeros',\n",
        "                             trainable=True)\n",
        "    self.u = self.add_weight(shape=(self.units,),\n",
        "                             initializer='random_normal',\n",
        "                             trainable=True)\n",
        "    self.alpha = self.add_weight(shape=(self.alpha_dim,),\n",
        "                             initializer='zeros',\n",
        "                             trainable=False)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    y_att = tf.math.tanh(tf.matmul(inputs, self.w) + self.b)\n",
        "    logits = tf.linalg.matvec(y_att, self.u)\n",
        "    # print(logits.shape)\n",
        "    self.alpha = tf.nn.softmax(logits)\n",
        "    return tf.transpose(tf.linalg.matvec(tf.transpose(inputs), self.alpha))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tZKxAZZ5rli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EnsembleBlock(layers.Layer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(EnsembleBlock, self).__init__()\n",
        "    self.ensemble_1 = Pathway_Attention(a=4, d=2, p=24)\n",
        "    self.ensemble_2 = Pathway_Attention(a=4, d=2, p=24)\n",
        "    self.ensemble_3 = Pathway_Attention(a=4, d=2, p=24)\n",
        "    self.ensemble_4 = Pathway_Attention(a=4, d=2, p=24)\n",
        "    self.ensemble_5 = Pathway_Attention(a=4, d=2, p=24)\n",
        "    # self.ensemble_6 = Pathway_Attention(a=4, d=2, p=112)\n",
        "    # self.ensemble_7 = Pathway_Attention(a=4, d=2, p=112)\n",
        "    # self.ensemble_8 = Pathway_Attention(a=4, d=2, p=112)\n",
        "    # self.ensemble_9 = Pathway_Attention(a=4, d=2, p=112)\n",
        "    # self.ensemble_10 = Pathway_Attention(a=4, d=2, p=110)\n",
        "    # self.ensemble_11 = Pathway_Attention(a=4, d=2, p=110)\n",
        "    self.final = Pathway_Attention(a=4, d=2, p=5)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    h1 = self.ensemble_1(inputs)\n",
        "    h2 = self.ensemble_2(inputs)\n",
        "    h3 = self.ensemble_3(inputs)\n",
        "    h4 = self.ensemble_4(inputs)\n",
        "    h5 = self.ensemble_5(inputs)\n",
        "    # h6 = self.ensemble_6(inputs)\n",
        "    # h7 = self.ensemble_7(inputs)\n",
        "    # h8 = self.ensemble_8(inputs)\n",
        "    # h9 = self.ensemble_9(inputs)\n",
        "    # h10 = self.ensemble_10(inputs)\n",
        "    # h11 = self.ensemble_11(inputs)\n",
        "    h_mgd = [h1, h2, h3, h4, h5]#, h6, h7, h8, h9, h10, h11]\n",
        "    h_mgd = tf.convert_to_tensor(h_mgd, dtype=tf.float32)\n",
        "    return self.final(h_mgd)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7NQmudC98GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MAE_Model(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MAE_Model, self).__init__()\n",
        "        self.h_fin = EnsembleBlock()\n",
        "        # self.ipt = tf.keras.layers.InputLayer(input_shape=(1,2), batch_size=None)\n",
        "        self.fc_1 = tf.keras.layers.Dense(16, activation='relu')\n",
        "        self.fc_2 = tf.keras.layers.Dense(8, activation='relu')\n",
        "        self.fc_3 = tf.keras.layers.Dense(4, activation='relu')\n",
        "        self.classifier = tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.h_fin(inputs)\n",
        "        x = tf.expand_dims(x, axis=0)\n",
        "        \n",
        "        # x = tf.reshape(x, (1,2))\n",
        "        # print(x)\n",
        "        # x = self.ipt(x)\n",
        "        x = self.fc_1(x)\n",
        "        x = self.fc_2(x)\n",
        "        x = self.fc_3(x)\n",
        "        return self.classifier(x)\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5fMOhbBb0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mae = MAE_Model()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqmWgKe2CIMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
        "# ce_loss_fn = tf.keras.losses.CategoricalCrossentropy()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p40HYLXQH9FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# acc_metric = tf.keras.metrics.Accuracy()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMmNemK3MiP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# target_names = ['class 0', 'class 1']\n",
        "# print(classification_report(y_true, y_test_preds, target_names=target_names))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OToABBWzxx6R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "679d06f0-73eb-4506-aa5a-63e36081815a"
      },
      "source": [
        "# ### TRAIN ###\n",
        "tf.keras.backend.clear_session()\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "mae1 = MAE_Model()\n",
        "acc_metric = tf.keras.metrics.Accuracy()\n",
        "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
        "ce_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "for epoch in range(10):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for tx, ty in train_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "      preds = mae1(tx)\n",
        "      # Compute reconstruction loss\n",
        "      # train_y = tf.one_hot(int(train_y), depth=2)\n",
        "      # train_y = tf.reshape(train_y, (1,2))\n",
        "      # print(y_train)\n",
        "      loss = ce_loss_fn(ty, preds)\n",
        "      # print(loss)\n",
        "\n",
        "    grads = tape.gradient(loss, mae1.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, mae1.trainable_weights))\n",
        "\n",
        "    acc_metric.update_state(ty, np.argmax(preds))\n",
        "\n",
        "  print('epoch %s: train mean accc = %s' % (epoch, acc_metric.result()))\n",
        "\n",
        "\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.7985437, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.8919903, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.9255663, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.94356793, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.95436895, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.9615696, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.9667129, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.9705704, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.97357064, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.97597086, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3XRf8H24F-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "9a7aa2e0-8e41-4bfc-ec93-7104e29ecc5d"
      },
      "source": [
        "\n",
        "### TEST ####\n",
        "y_1 = []\n",
        "y_0 = []\n",
        "for tx1, ty1 in test_dataset:\n",
        "  p = mae1(tx1)\n",
        "  # print(p)\n",
        "  y_1.append(np.argmax(p))\n",
        "  # y_2.append(p[0])\n",
        "  y_0.append(ty1)\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_0, y_1, target_names=target_names))\n",
        "# print(\"AUC: \", metrics.roc_auc_score(y_0, y_2))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.78      0.89      0.83        63\n",
            "     class 1       0.77      0.60      0.68        40\n",
            "\n",
            "    accuracy                           0.78       103\n",
            "   macro avg       0.78      0.74      0.75       103\n",
            "weighted avg       0.78      0.78      0.77       103\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fD6N4xYlCAP",
        "colab_type": "text"
      },
      "source": [
        "# Stratified K-fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxVsweIUMlSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = []"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUmf5m_5lEDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nRn9oTHlKld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7f33c48-09b8-4c03-d3e0-ef474f465adb"
      },
      "source": [
        "for train_index, test_index in skf.split(train_x, train_y):\n",
        "  X_train, X_val = train_x[train_index], train_x[test_index]\n",
        "  y_train, y_val = train_y[train_index], train_y[test_index]\n",
        "  dataset_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "  val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "\n",
        "  print(\"------------FOLD---------------\")\n",
        "  mae = MAE_Model()\n",
        "  acc_metric = tf.keras.metrics.Accuracy()\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "  ce_loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "  for epoch in range(10):\n",
        "    print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for tx, ty in dataset_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "        preds = mae(tx)\n",
        "        # Compute reconstruction loss\n",
        "        # train_y = tf.one_hot(int(train_y), depth=2)\n",
        "        # train_y = tf.reshape(train_y, (1,2))\n",
        "        # print(y_train)\n",
        "        loss = ce_loss_fn(ty, preds)\n",
        "        # print(loss)\n",
        "\n",
        "      grads = tape.gradient(loss, mae.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(grads, mae.trainable_weights))\n",
        "\n",
        "      acc_metric.update_state(ty, np.argmax(preds))\n",
        "\n",
        "    print('epoch %s: train mean accc = %s' % (epoch, acc_metric.result()))\n",
        "  \n",
        "  ### VAL ####\n",
        "  y_1 = []\n",
        "  y_0 = []\n",
        "  for tx1, ty1 in val_dataset:\n",
        "    p = mae(tx1)\n",
        "    # print(p)\n",
        "    y_1.append(np.argmax(p))\n",
        "    # y_2.append(p[0])\n",
        "    y_0.append(ty1)\n",
        "  target_names = ['class 0', 'class 1']\n",
        "  print(classification_report(y_0, y_1, target_names=target_names))\n",
        "  # print(\"AUC: \", metrics.roc_auc_score(y_0, y_2))\n",
        "\n",
        "\n",
        "  ## TEST ##\n",
        "  y_1 = []\n",
        "  y_0 = []\n",
        "  for tx1, ty1 in test_dataset:\n",
        "    p = mae(tx1)\n",
        "    # print(p)\n",
        "    y_1.append(np.argmax(p))\n",
        "    # y_2.append(p[0])\n",
        "    y_0.append(ty1)\n",
        "  target_names = ['class 0', 'class 1']\n",
        "  print(classification_report(y_0, y_1, target_names=target_names))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.5837838, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.59594595, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.602027, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.60324323, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.60405403, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.6046332, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.60506755, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.6054054, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.6056757, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.62      1.00      0.76        26\n",
            "     class 1       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.62        42\n",
            "   macro avg       0.31      0.50      0.38        42\n",
            "weighted avg       0.38      0.62      0.47        42\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.61      1.00      0.76        63\n",
            "     class 1       0.00      0.00      0.00        40\n",
            "\n",
            "    accuracy                           0.61       103\n",
            "   macro avg       0.31      0.50      0.38       103\n",
            "weighted avg       0.37      0.61      0.46       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.6108108, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.61737454, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.64966214, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.68108106, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.71054053, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      1.00      0.98        25\n",
            "     class 1       1.00      0.94      0.97        17\n",
            "\n",
            "    accuracy                           0.98        42\n",
            "   macro avg       0.98      0.97      0.98        42\n",
            "weighted avg       0.98      0.98      0.98        42\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.63      0.98      0.77        63\n",
            "     class 1       0.75      0.07      0.14        40\n",
            "\n",
            "    accuracy                           0.63       103\n",
            "   macro avg       0.69      0.53      0.45       103\n",
            "weighted avg       0.67      0.63      0.52       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.16981132, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.38948786, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.4627134, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.49932614, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.5212938, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.5359389, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.5463997, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.5754717, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.61126083, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.64420485, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.89      1.00      0.94        25\n",
            "     class 1       1.00      0.81      0.90        16\n",
            "\n",
            "    accuracy                           0.93        41\n",
            "   macro avg       0.95      0.91      0.92        41\n",
            "weighted avg       0.93      0.93      0.93        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.62      0.98      0.76        63\n",
            "     class 1       0.67      0.05      0.09        40\n",
            "\n",
            "    accuracy                           0.62       103\n",
            "   macro avg       0.64      0.52      0.43       103\n",
            "weighted avg       0.64      0.62      0.50       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.71428573, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.8301887, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.8481581, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.8530997, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.86091644, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.8724169, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.8864074, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.90026957, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.9113507, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.9202156, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       1.00      1.00      1.00        25\n",
            "     class 1       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           1.00        41\n",
            "   macro avg       1.00      1.00      1.00        41\n",
            "weighted avg       1.00      1.00      1.00        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.74      0.90      0.81        63\n",
            "     class 1       0.77      0.50      0.61        40\n",
            "\n",
            "    accuracy                           0.75       103\n",
            "   macro avg       0.75      0.70      0.71       103\n",
            "weighted avg       0.75      0.75      0.73       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.88409704, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.8908356, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.90206647, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.91778976, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.93045825, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.9415993, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.94994223, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.95619947, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.9610662, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.96495956, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       1.00      1.00      1.00        25\n",
            "     class 1       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           1.00        41\n",
            "   macro avg       1.00      1.00      1.00        41\n",
            "weighted avg       1.00      1.00      1.00        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.72      0.97      0.82        63\n",
            "     class 1       0.89      0.40      0.55        40\n",
            "\n",
            "    accuracy                           0.75       103\n",
            "   macro avg       0.80      0.68      0.69       103\n",
            "weighted avg       0.78      0.75      0.72       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.65121293, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.6927224, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.7258375, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.7537062, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.7768793, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.796496, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      1.00      0.98        25\n",
            "     class 1       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        41\n",
            "   macro avg       0.98      0.97      0.97        41\n",
            "weighted avg       0.98      0.98      0.98        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.63      0.98      0.77        63\n",
            "     class 1       0.75      0.07      0.14        40\n",
            "\n",
            "    accuracy                           0.63       103\n",
            "   macro avg       0.69      0.53      0.45       103\n",
            "weighted avg       0.67      0.63      0.52       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.61185986, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.61051214, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6100629, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.60983825, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.6097035, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.60961366, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.60954946, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.625, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.65378857, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.6843666, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      1.00      0.98        25\n",
            "     class 1       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        41\n",
            "   macro avg       0.98      0.97      0.97        41\n",
            "weighted avg       0.98      0.98      0.98        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.62      0.98      0.76        63\n",
            "     class 1       0.67      0.05      0.09        40\n",
            "\n",
            "    accuracy                           0.62       103\n",
            "   macro avg       0.64      0.52      0.43       103\n",
            "weighted avg       0.64      0.62      0.50       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.6603774, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.7214735, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.7634771, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.7946092, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.819407, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.83904505, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.8554582, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.8691225, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.880593, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       1.00      1.00      1.00        25\n",
            "     class 1       1.00      1.00      1.00        16\n",
            "\n",
            "    accuracy                           1.00        41\n",
            "   macro avg       1.00      1.00      1.00        41\n",
            "weighted avg       1.00      1.00      1.00        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.64      0.98      0.77        63\n",
            "     class 1       0.83      0.12      0.22        40\n",
            "\n",
            "    accuracy                           0.65       103\n",
            "   macro avg       0.74      0.55      0.50       103\n",
            "weighted avg       0.71      0.65      0.56       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.6091644, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.61      1.00      0.76        25\n",
            "     class 1       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.61        41\n",
            "   macro avg       0.30      0.50      0.38        41\n",
            "weighted avg       0.37      0.61      0.46        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.61      1.00      0.76        63\n",
            "     class 1       0.00      0.00      0.00        40\n",
            "\n",
            "    accuracy                           0.61       103\n",
            "   macro avg       0.31      0.50      0.38       103\n",
            "weighted avg       0.37      0.61      0.46       103\n",
            "\n",
            "------------FOLD---------------\n",
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer mae__model_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "epoch 0: train mean accc = tf.Tensor(0.63072777, shape=(), dtype=float32)\n",
            "Start of epoch 1\n",
            "epoch 1: train mean accc = tf.Tensor(0.6347709, shape=(), dtype=float32)\n",
            "Start of epoch 2\n",
            "epoch 2: train mean accc = tf.Tensor(0.6621743, shape=(), dtype=float32)\n",
            "Start of epoch 3\n",
            "epoch 3: train mean accc = tf.Tensor(0.69137466, shape=(), dtype=float32)\n",
            "Start of epoch 4\n",
            "epoch 4: train mean accc = tf.Tensor(0.722372, shape=(), dtype=float32)\n",
            "Start of epoch 5\n",
            "epoch 5: train mean accc = tf.Tensor(0.7511231, shape=(), dtype=float32)\n",
            "Start of epoch 6\n",
            "epoch 6: train mean accc = tf.Tensor(0.77628034, shape=(), dtype=float32)\n",
            "Start of epoch 7\n",
            "epoch 7: train mean accc = tf.Tensor(0.7981806, shape=(), dtype=float32)\n",
            "Start of epoch 8\n",
            "epoch 8: train mean accc = tf.Tensor(0.81611264, shape=(), dtype=float32)\n",
            "Start of epoch 9\n",
            "epoch 9: train mean accc = tf.Tensor(0.8315364, shape=(), dtype=float32)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.96      1.00      0.98        25\n",
            "     class 1       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        41\n",
            "   macro avg       0.98      0.97      0.97        41\n",
            "weighted avg       0.98      0.98      0.98        41\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.62      0.98      0.76        63\n",
            "     class 1       0.67      0.05      0.09        40\n",
            "\n",
            "    accuracy                           0.62       103\n",
            "   macro avg       0.64      0.52      0.43       103\n",
            "weighted avg       0.64      0.62      0.50       103\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r5mGc95litT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "6bd8552a-3c1c-42ba-c4ac-6d9860fdc5f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = [i for i in range(24)]\n",
        "plt.bar(x, mae1.h_fin.ensemble_1.alpha)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 24 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYdD6r4Ttwl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df = pd.DataFrame(mae.h_fin.ensemble_1.alpha.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_odIdzhuJsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathway_file_map = {'hsa01522 .csv': 0, 'hsa03320 .csv': 1, 'hsa04010 .csv': 2, 'hsa04012 .csv': 3, 'hsa04014 .csv': 4, 'hsa04015 .csv': 5, 'hsa04020 .csv': 6, 'hsa04022 .csv': 7, 'hsa04024 .csv': 8, 'hsa04062 .csv': 9, 'hsa04064 .csv': 10, 'hsa04066 .csv': 11, 'hsa04068 .csv': 12, 'hsa04071 .csv': 13, 'hsa04072 .csv': 14, 'hsa04110 .csv': 15, 'hsa04115 .csv': 16, 'hsa04137 .csv': 17, 'hsa04140 .csv': 18, 'hsa04144 .csv': 19, 'hsa04145 .csv': 20, 'hsa04150 .csv': 21, 'hsa04151 .csv': 22, 'hsa04152 .csv': 23, 'hsa04210 .csv': 24, 'hsa04211 .csv': 25, 'hsa04216 .csv': 26, 'hsa04217 .csv': 27, 'hsa04218 .csv': 28, 'hsa04261 .csv': 29, 'hsa04270 .csv': 30, 'hsa04310 .csv': 31, 'hsa04340 .csv': 32, 'hsa04350 .csv': 33, 'hsa04360 .csv': 34, 'hsa04370 .csv': 35, 'hsa04371 .csv': 36, 'hsa04380 .csv': 37, 'hsa04390 .csv': 38, 'hsa04510 .csv': 39, 'hsa04520 .csv': 40, 'hsa04530 .csv': 41, 'hsa04550 .csv': 42, 'hsa04610 .csv': 43, 'hsa04611 .csv': 44, 'hsa04620 .csv': 45, 'hsa04621 .csv': 46, 'hsa04622 .csv': 47, 'hsa04625 .csv': 48, 'hsa04630 .csv': 49, 'hsa04650 .csv': 50, 'hsa04657 .csv': 51, 'hsa04658 .csv': 52, 'hsa04659 .csv': 53, 'hsa04660 .csv': 54, 'hsa04662 .csv': 55, 'hsa04664 .csv': 56, 'hsa04666 .csv': 57, 'hsa04668 .csv': 58, 'hsa04670 .csv': 59, 'hsa04713 .csv': 60, 'hsa04714 .csv': 61, 'hsa04720 .csv': 62, 'hsa04722 .csv': 63, 'hsa04723 .csv': 64, 'hsa04724 .csv': 65, 'hsa04725 .csv': 66, 'hsa04726 .csv': 67, 'hsa04728 .csv': 68, 'hsa04730 .csv': 69, 'hsa04750 .csv': 70, 'hsa04810 .csv': 71, 'hsa04910 .csv': 72, 'hsa04911 .csv': 73, 'hsa04912 .csv': 74, 'hsa04913 .csv': 75, 'hsa04915 .csv': 76, 'hsa04916 .csv': 77, 'hsa04917 .csv': 78, 'hsa04918 .csv': 79, 'hsa04919 .csv': 80, 'hsa04920 .csv': 81, 'hsa04921 .csv': 82, 'hsa04922 .csv': 83, 'hsa04923 .csv': 84, 'hsa04924 .csv': 85, 'hsa04925 .csv': 86, 'hsa04926 .csv': 87, 'hsa04927 .csv': 88, 'hsa04928 .csv': 89, 'hsa04929 .csv': 90, 'hsa04935 .csv': 91, 'hsa04960 .csv': 92, 'hsa04961 .csv': 93, 'hsa04962 .csv': 94, 'hsa04970 .csv': 95, 'hsa04971 .csv': 96, 'hsa04972 .csv': 97, 'hsa04973 .csv': 98, 'hsa04976 .csv': 99, 'hsa04978 .csv': 100, 'hsa04979 .csv': 101, 'hsa05200 .csv': 102, 'hsa05202 .csv': 103, 'hsa05204 .csv': 104, 'hsa05205 .csv': 105, 'hsa05211 .csv': 106, 'hsa05230 .csv': 107, 'hsa05231 .csv': 108, 'hsa05235 .csv': 109}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwVxifmSuW7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list out keys and values separately \n",
        "key_list = list(pathway_file_map.keys()) \n",
        "val_list = list(pathway_file_map.values()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8l82g5X231c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['pathway'] = key_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpsyeho63B3Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "94770910-bbe2-4343-f67b-74bd765f4189"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>pathway</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa01522 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa03320 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa04010 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa04012 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa04014 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa05205 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa05211 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa05230 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa05231 .csv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0.009091</td>\n",
              "      <td>hsa05235 .csv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>110 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0        pathway\n",
              "0    0.009091  hsa01522 .csv\n",
              "1    0.009091  hsa03320 .csv\n",
              "2    0.009091  hsa04010 .csv\n",
              "3    0.009091  hsa04012 .csv\n",
              "4    0.009091  hsa04014 .csv\n",
              "..        ...            ...\n",
              "105  0.009091  hsa05205 .csv\n",
              "106  0.009091  hsa05211 .csv\n",
              "107  0.009091  hsa05230 .csv\n",
              "108  0.009091  hsa05231 .csv\n",
              "109  0.009091  hsa05235 .csv\n",
              "\n",
              "[110 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFS_4ZmM3Cmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.concatenate([train_x, test_x])\n",
        "full_dataset = tf.data.Dataset.from_tensor_slices((X, Y))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5tATv8YFTSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathway_scores = []"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wtCRyHuFN62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for patient, label in full_dataset:\n",
        "  _ = mae1(patient)\n",
        "  scores = mae1.h_fin.ensemble_1.alpha.numpy()\n",
        "  scores_norm = scores/np.linalg.norm(scores)\n",
        "  pathway_scores.append(scores_norm)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eb140flFo99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "875adebc-30df-4f37-854f-ed8dfaf10bd6"
      },
      "source": [
        "from matplotlib.pyplot import figure\n",
        "figure(num=None, figsize=(30, 60), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.imshow(np.asarray(pathway_scores).T, cmap='Reds', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2400x4800 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP3lfscUHXON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "015206bf-48b0-4b29-a820-acdf624d38f4"
      },
      "source": [
        "pathway_scores[410][26]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.095346265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS-A6kOjIJ0g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f61d6989-bd4b-424f-b1b8-29265c639620"
      },
      "source": [
        "pathway_scores[101][26]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09534626"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBo41AenI0-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathway_scores[830][26]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8H1qH-wJBZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "key_list[26] #Ferroptosis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdtkb0PXJGaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot([0.96, 0.97, 0.95, 0.97, 0.97])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTYWIGCyj3AO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathway_scores_df = pd.DataFrame(pathway_scores, columns=key_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znmnFXHrJUmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathway_scores_df.to_csv('./pathway_scores_gcn_mae_kirc_stage.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhOSQTPbJnxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scores for best performing pathways (individually) \n",
        "pathway_to_see = ['hsa04530 .csv', 'hsa04068 .csv', 'hsa04010 .csv', 'hsa05211 .csv']\n",
        "for p in pathway_to_see:\n",
        "  print(p[:-5])\n",
        "  idx = pathway_file_map[p]\n",
        "  kirp_score = np.mean([x[idx] for x in pathway_scores[0:290]])\n",
        "  kirc_score = np.mean([x[idx] for x in pathway_scores[290:808]])\n",
        "  kich_score = np.mean([x[idx] for x in pathway_scores[808:]])\n",
        "  print(kirp_score, kirc_score, kich_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywmdh_H_LZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scores for least performing pathways (individually) \n",
        "pathway_to_see = ['hsa04216 .csv', 'hsa04657 .csv', 'hsa04973 .csv']\n",
        "for p in pathway_to_see:\n",
        "  print(p[:-5])\n",
        "  idx = pathway_file_map[p]\n",
        "  kirp_score = np.mean([x[idx] for x in pathway_scores[0:290]])\n",
        "  kirc_score = np.mean([x[idx] for x in pathway_scores[290:808]])\n",
        "  kich_score = np.mean([x[idx] for x in pathway_scores[808:]])\n",
        "  print(kirp_score, kirc_score, kich_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygL1cVEhLjUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_model_stats = []\n",
        "\n",
        "for p in key_list:\n",
        "  print(p[:-5])\n",
        "  idx = pathway_file_map[p]\n",
        "  kirp_score = np.mean([x[idx] for x in pathway_scores[0:290]])\n",
        "  kirc_score = np.mean([x[idx] for x in pathway_scores[290:808]])\n",
        "  kich_score = np.mean([x[idx] for x in pathway_scores[808:]])\n",
        "  variation = np.var([kirp_score, kirc_score, kich_score], ddof=1)\n",
        "  diff_kirp_kirc = abs(kirp_score-kirc_score)\n",
        "  diff_kirp_kich = abs(kirp_score-kich_score)\n",
        "  diff_kirc_kich = abs(kirc_score-kich_score)\n",
        "  attention_model_stats.append([p[:-5],kirp_score, kirc_score, kich_score, variation, diff_kirp_kirc, diff_kirp_kich, diff_kirc_kich])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yoMQ8JVOhrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_model_stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aZ604pgP5VQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_model_stats_df = pd.DataFrame(attention_model_stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYB7gB5CXbd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_model_stats_df.to_csv(\"attention_model__kirc_stage_stats.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrUB7EeLVgGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}