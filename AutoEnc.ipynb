{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEnc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-XFlYNag3vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2d29b06f-0340-45ba-f253-77138d3a62e2"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import spektral\n",
        "np.random.seed(0)\n",
        "import os \n",
        "\n",
        "path = '/content/drive/My Drive/IIITH/GCN_KEGG/GCN_Dataset/CSV'\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clinical_KICH_81_tumors.csv',\n",
              " 'Clinical_KIRP_290_tumors.csv',\n",
              " 'Clinical_KIRC_518_tumors.csv',\n",
              " 'KICH_81_tumors_log_transformed.csv',\n",
              " 'KIRP_290_tumors_log_transformed.csv',\n",
              " 'KIRC_518_tumors_log_transformed.csv',\n",
              " '.DS_Store']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2B7-SH9hEAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(path, filename, transpose=True):\n",
        "    '''\n",
        "        Loads the dataset and converts into its transpose with appropriate columns\n",
        "    '''\n",
        "    df = pd.read_csv(os.path.join(path, filename))\n",
        "    df.rename(columns={\"Unnamed: 0\": \"pid\"}, inplace=True)\n",
        "    if transpose:\n",
        "        df = df.astype({\"pid\": str})\n",
        "        df = df.T\n",
        "        new_header = df.iloc[0] \n",
        "        df = df[1:]\n",
        "        df.columns = new_header\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw2SoPwG41pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
        "    tsne = TSNE(n_components=2, random_state=0)\n",
        "    X_t = tsne.fit_transform(x1)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='Non Fraud')\n",
        "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Fraud')\n",
        "\n",
        "    plt.legend(loc='best');\n",
        "    # plt.savefig(name);\n",
        "    plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sADcsmRi9sC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features_matrix(pathway, dataframe):\n",
        "\n",
        "  genes_used = set()\n",
        "\n",
        "  for i in range(len(pathway)):\n",
        "      genes_used.add(pathway.iloc[i]['from'][4:])\n",
        "      genes_used.add(pathway.iloc[i]['to'][4:])\n",
        "\n",
        "  to_remove = []\n",
        "\n",
        "  for gene in genes_used:\n",
        "      if gene not in dataframe.columns:\n",
        "          to_remove.append(gene)\n",
        "\n",
        "  for gene in to_remove:\n",
        "    genes_used.remove(gene)\n",
        "\n",
        "  genes_used = list(genes_used)\n",
        "  genes_used.sort()\n",
        "\n",
        "  return genes_used"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nah03WDZ9zbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kegg_pathways_path = '/content/drive/My Drive/IIITH/GCN_KEGG/KEGG_csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEpfRL4-hIAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_kirc = load_dataset(path,'KIRC_518_tumors_log_transformed.csv',transpose=True)\n",
        "patient_data_kirc = load_dataset(path,'Clinical_KIRC_518_tumors.csv',transpose=False)\n",
        "pid_kirc_drop1 = patient_data_kirc[patient_data_kirc['ajcc_pathologic_tumor_stage']=='[Not Available]'].pid\n",
        "pid_kirc_drop2 = patient_data_kirc[patient_data_kirc['ajcc_pathologic_tumor_stage']=='[Discrepancy]'].pid\n",
        "patient_data_kirc.drop(patient_data_kirc[patient_data_kirc['ajcc_pathologic_tumor_stage']=='[Not Available]'].index, inplace=True )\n",
        "patient_data_kirc.drop(patient_data_kirc[patient_data_kirc['ajcc_pathologic_tumor_stage']=='[Discrepancy]'].index, inplace=True )\n",
        "df_kirc.drop(pid_kirc_drop1,inplace=True)\n",
        "df_kirc.drop(pid_kirc_drop2,inplace=True)\n",
        "\n",
        "y_kirc=[]\n",
        "for pid in df_kirc.index:\n",
        "    stage=patient_data_kirc[patient_data_kirc['pid']==pid]['ajcc_pathologic_tumor_stage']\n",
        "    stage = stage.values[0]\n",
        "    if stage=='Stage I':\n",
        "        y_kirc.append(0)\n",
        "    elif stage=='Stage II':\n",
        "        y_kirc.append(0)\n",
        "    elif stage=='Stage III':\n",
        "        y_kirc.append(1)\n",
        "    elif stage=='Stage IV':\n",
        "        y_kirc.append(1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvINO0r_jshn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# features_to_use = set()\n",
        "# data_subset = data_train\n",
        "# data_subset = data_subset.assign(y=pd.Series(y_train).values)\n",
        "# data_subset = data_subset.apply(pd.to_numeric) \n",
        "# corrMatrix = data_subset.corr()\n",
        "# features_to_use.update(corrMatrix[corrMatrix['y']<-0.3].index.tolist())\n",
        "# features_to_use.update(corrMatrix[corrMatrix['y']>0.3].index.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0957hTwj00H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # features_to_use.remove('y')\n",
        "# features_to_use = {'100129583',\n",
        "#  '100289341',\n",
        "#  '10643',\n",
        "#  '11065',\n",
        "#  '11162',\n",
        "#  '148808',\n",
        "#  '1748',\n",
        "#  '196047',\n",
        "#  '201161',\n",
        "#  '2018',\n",
        "#  '26275',\n",
        "#  '3131',\n",
        "#  '36',\n",
        "#  '3706',\n",
        "#  '4306',\n",
        "#  '5047',\n",
        "#  '51054',\n",
        "#  '53833',\n",
        "#  '55165',\n",
        "#  '5522',\n",
        "#  '55325',\n",
        "#  '55521',\n",
        "#  '6262',\n",
        "#  '6716',\n",
        "#  '7691',\n",
        "#  '7923',\n",
        "#  '79944',\n",
        "#  '81796',\n",
        "#  '829',\n",
        "#  '84866',\n",
        "#  '9603'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDeXT3cmhKnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = df_kirc[list(features_to_use)]\n",
        "# # y = y_kirc\n",
        "# y_kirc = np.asarray(y_kirc)\n",
        "# data = data.assign(y=pd.Series(y_kirc).values)\n",
        "# data = data.apply(pd.to_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN6GBn40jf0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# data_train, data_test, y_train, y_test = train_test_split(data, y_kirc, test_size=0.1, random_state=0, stratify=y_kirc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyrgHApllFyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1f88265f-cedf-490f-9303-1641d068bb47"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import NuSVC, SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import preprocessing \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Owhrn5UHuGRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X = data_train.drop(['y'], axis=1)\n",
        "# y = data_train['y']\n",
        "# y = y.values\n",
        "\n",
        "# ## define the model\n",
        "# input_layer = Input(shape=(X.shape[1],))\n",
        "# encoded = Dense(200, activation='tanh', activity_regularizer=regularizers.l2(10e-5))(input_layer)\n",
        "# encoded = Dense(100, activation='tanh')(encoded)\n",
        "# encoded = Dense(50, activation='relu')(encoded)\n",
        "# decoded = Dense(50, activation='tanh')(encoded)\n",
        "# decoded = Dense(100, activation='tanh')(decoded)\n",
        "# decoded = Dense(200, activation='tanh')(decoded)\n",
        "# output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
        "\n",
        "# autoencoder = Model(input_layer, output_layer)\n",
        "# autoencoder.compile(optimizer=\"rmsprop\", loss=\"mse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_auYDzqwR-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test = data_test.drop(['y'], axis=1)\n",
        "# scaler = preprocessing.MinMaxScaler()\n",
        "# scaler.fit(X.values)\n",
        "# X_scale = scaler.transform(X.values)\n",
        "# test_x_scale = scaler.transform(test.values)\n",
        "\n",
        "# x_early, x_late = X_scale[y == 0], X_scale[y == 1]\n",
        "# autoencoder.fit(x_early, x_early, epochs = 20, validation_split=0.1, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqvFWbHxwluL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hidden_representation = Sequential()\n",
        "# hidden_representation.add(autoencoder.layers[0])\n",
        "# hidden_representation.add(autoencoder.layers[1])\n",
        "# hidden_representation.add(autoencoder.layers[2])\n",
        "# hidden_representation.add(autoencoder.layers[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHyfQzZxyeyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI1APdqIw5Hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# early_hid_rep = hidden_representation.predict(x_early)\n",
        "# late_hid_rep = hidden_representation.predict(x_late)\n",
        "\n",
        "# rep_x = np.append(early_hid_rep, late_hid_rep, axis = 0)\n",
        "# y_n = np.zeros(early_hid_rep.shape[0])\n",
        "# y_f = np.ones(late_hid_rep.shape[0])\n",
        "# rep_y = np.append(y_n, y_f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAnDsyvnxhs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tsne_plot(rep_x, rep_y, \"latent_representation_train.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZlTXx2xxDBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.1, random_state=0, stratify=rep_y)\n",
        "# clf1 = LogisticRegression().fit(train_x, train_y)\n",
        "# pred_y = clf1.predict(val_x)\n",
        "\n",
        "# print(classification_report(val_y, pred_y))\n",
        "# print(accuracy_score(val_y, pred_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEb5zim933nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_rep_x = hidden_representation.predict(test_x_scale)\n",
        "\n",
        "# pred_y_test1 = clf1.predict(test_rep_x)\n",
        "\n",
        "# print(accuracy_score(y_test, pred_y_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJCU5qLiDmoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "77324d64-bb6b-485b-9394-719ac7beb2f7"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lda_scores= []\n",
        "files_used = []\n",
        "\n",
        "files_to_use = os.listdir(kegg_pathways_path)\n",
        "files_to_use.sort()\n",
        "\n",
        "for file in files_to_use:\n",
        "\tif 'hsa' not in file:\n",
        "\t\tcontinue\n",
        "\tpathway = pd.read_csv(os.path.join(kegg_pathways_path,file))\n",
        "\tpathway.rename(columns={\"Unnamed: 0\": \"idx\"}, inplace=True)\n",
        "\n",
        "\tfeatures_to_use = get_features_matrix(pathway, df_kirc)\n",
        "\n",
        "\tif len(features_to_use)<5:\n",
        "\t\tcontinue\n",
        "\tdata = df_kirc[features_to_use]\n",
        "\ty_kirc = np.asarray(y_kirc)\n",
        "\tdata = data.assign(y=pd.Series(y_kirc).values)\n",
        "\tdata = data.apply(pd.to_numeric)\n",
        "\tdata_train, data_test, y_train, y_test = train_test_split(data, y_kirc, test_size=0.2, random_state=0, stratify=y_kirc)\n",
        "\n",
        "\n",
        "\tX = data_train.drop(['y'], axis=1)\n",
        "\ty = data_train['y']\n",
        "\ty = y.values\n",
        "\n",
        "\t## define the model\n",
        "\tinput_layer = Input(shape=(X.shape[1],))\n",
        "\tencoded = Dense(128, activation='tanh', activity_regularizer=regularizers.l2(10e-5))(input_layer)\n",
        "\tencoded = Dense(128, activation='tanh')(encoded)\n",
        "\tencoded = Dense(64, activation='relu')(encoded)\n",
        "\tdecoded = Dense(64, activation='tanh')(encoded)\n",
        "\tdecoded = Dense(128, activation='tanh')(decoded)\n",
        "\tdecoded = Dense(128, activation='tanh')(decoded)\n",
        "\toutput_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
        "\n",
        "\tautoencoder = Model(input_layer, output_layer)\n",
        "\tautoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")\n",
        "\n",
        "\ttest = data_test.drop(['y'], axis=1)\n",
        "\tscaler = preprocessing.MinMaxScaler()\n",
        "\tscaler.fit(X.values)\n",
        "\tX_scale = scaler.transform(X.values)\n",
        "\ttest_x_scale = scaler.transform(test.values)\n",
        "\n",
        "\tx_early, x_late = X_scale[y == 0], X_scale[y == 1]\n",
        "\tautoencoder.fit(x_early, x_early, epochs = 15, validation_split=0.0, batch_size=4, verbose=0)\n",
        "\n",
        "\thidden_representation = Sequential()\n",
        "\thidden_representation.add(autoencoder.layers[0])\n",
        "\thidden_representation.add(autoencoder.layers[1])\n",
        "\thidden_representation.add(autoencoder.layers[2])\n",
        "\thidden_representation.add(autoencoder.layers[3])\n",
        "\n",
        "\n",
        "\n",
        "\tearly_hid_rep = hidden_representation.predict(x_early)\n",
        "\tlate_hid_rep = hidden_representation.predict(x_late)\n",
        "\n",
        "\trep_x = np.append(early_hid_rep, late_hid_rep, axis = 0)\n",
        "\ty_n = np.zeros(early_hid_rep.shape[0])\n",
        "\ty_f = np.ones(late_hid_rep.shape[0])\n",
        "\trep_y = np.append(y_n, y_f)\n",
        "\n",
        "\t# train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.1, random_state=0, stratify=rep_y)\n",
        "\tclf1 = LogisticRegression(max_iter=1500, random_state=0)\n",
        "\tscores = cross_val_score(clf1, rep_x, rep_y, cv=10)\n",
        "\tval_score = np.mean(scores)\n",
        "\t\n",
        "\tclf1 = LogisticRegression(max_iter=1500, random_state=0).fit(rep_x, rep_y)\n",
        "\n",
        "\ttest_rep_x = hidden_representation.predict(test_x_scale)\n",
        "\n",
        "\tpred_y_test1 = clf1.predict(test_rep_x)\n",
        "\n",
        "\tscore = accuracy_score(y_test, pred_y_test1)\n",
        "\n",
        "\n",
        "\t# score = eclf3.score(X_test, y_test)\n",
        " \n",
        "\tlda_scores.append(score)\n",
        "\tprint(file, val_score, score)\n",
        "\ttf.keras.backend.clear_session()\n",
        "\tif val_score>0.78:\n",
        "\t\tfiles_used.append(file)\n",
        "\t\t\n",
        "\n",
        "\t\t# gcn_pathway_output = eclf3.predict_proba(X)\n",
        "\t\t# filename_output_csv = os.path.join(\"/content/drive/My Drive/IIITH/GCN_KEGG/KIRC_Stage_TSNE_PCA_Plots/GCN_Pathway_output_scores\",file)\n",
        "\t\t# np.savetxt(filename_output_csv,gcn_pathway_output)    \n",
        "\t\n",
        "\n",
        "\t\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hsa00010 .csv 0.6481416957026712 0.6796116504854369\n",
            "hsa00051 .csv 0.6529616724738675 0.6601941747572816\n",
            "hsa00250 .csv 0.6891986062717769 0.7475728155339806\n",
            "hsa00260 .csv 0.6358885017421602 0.6601941747572816\n",
            "hsa00280 .csv 0.6822299651567943 0.7087378640776699\n",
            "hsa00830 .csv 0.6770615563298489 0.6699029126213593\n",
            "hsa00860 .csv 0.6795005807200928 0.6796116504854369\n",
            "hsa01522 .csv 0.6702671312427408 0.7378640776699029\n",
            "hsa03320 .csv 0.6628339140534262 0.6699029126213593\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d28e82de2cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx_early\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_late\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_scale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_early\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_early\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mhidden_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    315\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# use the new accumulator and the *old* delta_accumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_a\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mnew_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msqrt\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mnp_implementation\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m     \"\"\"\n\u001b[0;32m-> 1913\u001b[0;31m     \u001b[0mzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1914\u001b[0m     \u001b[0minf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_to_tensor\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \"\"\"\n\u001b[0;32m--> 539\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    304\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    305\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 306\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    307\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3327\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3328\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3392\u001b[0m     \u001b[0;31m# this op type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3394\u001b[0;31m       \u001b[0mmapped_op_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_override_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3395\u001b[0m       op._set_attr(\"_gradient_op_type\",  # pylint: disable=protected-access\n\u001b[1;32m   3396\u001b[0m                    attr_value_pb2.AttrValue(s=compat.as_bytes(mapped_op_type)))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2219\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2220\u001b[0m     \u001b[0;34m\"\"\"The type of the op (e.g. `\"MatMul\"`).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOpType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjyziXLi_USI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(lda_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aoZCo46DvHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "72198b6d-e419-4315-8cfb-1f1f954a3232"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "features_to_use = set()\n",
        "\n",
        "lda_scores= []\n",
        "files_used = []\n",
        "\n",
        "files_to_use = os.listdir(kegg_pathways_path)\n",
        "files_to_use.sort()\n",
        "\n",
        "for file in [\n",
        "'hsa04622 .csv',\n",
        "'hsa00250 .csv']:\n",
        "\tif 'hsa' not in file:\n",
        "\t\tcontinue\n",
        "\tpathway = pd.read_csv(os.path.join(kegg_pathways_path,file))\n",
        "\tpathway.rename(columns={\"Unnamed: 0\": \"idx\"}, inplace=True)\n",
        "\n",
        "\tfeatures_to_use.update(get_features_matrix(pathway, df_kirc))\n",
        "\n",
        "\t# if len(features_to_use)<5:\n",
        "\t# \tcontinue\n",
        "print(len(features_to_use))\n",
        "data = df_kirc[list(features_to_use)]\n",
        "y_kirc = np.asarray(y_kirc)\n",
        "data = data.assign(y=pd.Series(y_kirc).values)\n",
        "data = data.apply(pd.to_numeric)\n",
        "data_train, data_test, y_train, y_test = train_test_split(data, y_kirc, test_size=0.2, random_state=0, stratify=y_kirc)\n",
        "\n",
        "\n",
        "X = data_train.drop(['y'], axis=1)\n",
        "y = data_train['y']\n",
        "y = y.values\n",
        "\n",
        "## define the model\n",
        "input_layer = Input(shape=(X.shape[1],))\n",
        "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l2(10e-5))(input_layer)\n",
        "encoded = Dense(50, activation='relu', activity_regularizer=regularizers.l2(10e-5))(encoded)\n",
        "decoded = Dense(50, activation='tanh', activity_regularizer=regularizers.l2(10e-5))(encoded)\n",
        "decoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l2(10e-5))(decoded)\n",
        "output_layer = Dense(X.shape[1], activation='relu')(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, output_layer)\n",
        "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")\n",
        "\n",
        "test = data_test.drop(['y'], axis=1)\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "scaler.fit(X.values)\n",
        "X_scale = scaler.transform(X.values)\n",
        "test_x_scale = scaler.transform(test.values)\n",
        "\n",
        "x_early, x_late = X_scale[y == 0], X_scale[y == 1]\n",
        "autoencoder.fit(x_early, x_early, epochs = 20, validation_split=0.0, batch_size=4, verbose=0)\n",
        "\n",
        "hidden_representation = Sequential()\n",
        "hidden_representation.add(autoencoder.layers[0])\n",
        "hidden_representation.add(autoencoder.layers[1])\n",
        "hidden_representation.add(autoencoder.layers[2])\n",
        "# hidden_representation.add(autoencoder.layers[3])\n",
        "\n",
        "\n",
        "\n",
        "early_hid_rep = hidden_representation.predict(x_early)\n",
        "late_hid_rep = hidden_representation.predict(x_late)\n",
        "\n",
        "rep_x = np.append(early_hid_rep, late_hid_rep, axis = 0)\n",
        "y_n = np.zeros(early_hid_rep.shape[0])\n",
        "y_f = np.ones(late_hid_rep.shape[0])\n",
        "rep_y = np.append(y_n, y_f)\n",
        "\n",
        "# train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.1, random_state=0, stratify=rep_y)\n",
        "clf1 = LogisticRegression()\n",
        "scores = cross_val_score(clf1, rep_x, rep_y, cv=10)\n",
        "val_score = np.mean(scores)\n",
        "\n",
        "clf1 = LogisticRegression().fit(rep_x, rep_y)\n",
        "\n",
        "test_rep_x = hidden_representation.predict(test_x_scale)\n",
        "\n",
        "pred_y_test1 = clf1.predict(test_rep_x)\n",
        "\n",
        "score = accuracy_score(y_test, pred_y_test1)\n",
        "\n",
        "\n",
        "# score = eclf3.score(X_test, y_test)\n",
        "\n",
        "lda_scores.append(score)\n",
        "print(file, val_score, score)\n",
        "tf.keras.backend.clear_session()\n",
        "  \n",
        "\n",
        "  # gcn_pathway_output = eclf3.predict_proba(X)\n",
        "  # filename_output_csv = os.path.join(\"/content/drive/My Drive/IIITH/GCN_KEGG/KIRC_Stage_TSNE_PCA_Plots/GCN_Pathway_output_scores\",file)\n",
        "  # np.savetxt(filename_output_csv,gcn_pathway_output)    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TookPWjQSrTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred1 = clf1.predict_proba(test_rep_x)\n",
        "print(roc_auc_score(y_test, y_pred1[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M8oeQbVUNE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}